# SAC-RL-Navigation

A reinforcement learning project that trains an autonomous agent using the **Soft Actor-Critic (SAC)** algorithm in a 3D **PyBullet** environment. The agent learns to navigate toward a target position while avoiding static obstacles using ray-based observations.

---

## ğŸš€ Features

- âœ… Continuous action space control with Soft Actor-Critic (SAC)
- âœ… Obstacle-aware navigation in a 3D simulation
- âœ… Custom PyBullet environment with goal and random obstacles
- âœ… Ray-based perception (8 azimuth x 5 elevation rays)
- âœ… Replay buffer saving and full checkpointing
- âœ… Training resume support

---

## ğŸ§  Algorithms

This project uses the **Soft Actor-Critic (SAC)** algorithm, an off-policy actor-critic method based on the maximum entropy framework. It provides a trade-off between exploration and exploitation by encouraging stochastic policies.

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/yourusername/SAC-RL-Navigation.git
cd SAC-RL-Navigation
pip install -r requirements.txt
